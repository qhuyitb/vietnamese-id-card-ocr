# src/parsers/field_parser.py
import re
from typing import Dict, Optional, List
from datetime import datetime

class FieldParser:
    def __init__(self):
        """Initialize parser"""
        pass
    
    def parse(self, full_text: str, ocr_results: List) -> Dict[str, Optional[str]]:
        """Parse th√¥ng tin - t·ªïng qu√°t cho m·ªçi lo·∫°i th·∫ª"""
        # Clean text tr∆∞·ªõc
        text = self._clean_text(full_text)
        
        data = {
            'card_type': self.detect_card_type(text),  # ‚Üê TH√äM NH·∫¨N DI·ªÜN LO·∫†I TH·∫∫
            'id_number': self._extract_id_number(text),
            'full_name': self._extract_name(text),
            'date_of_birth': self._extract_dob(text),
            'gender': self._extract_gender(text),
            'nationality': self._extract_nationality(text),
            'place_of_origin': self._extract_origin(text),
            'place_of_residence': self._extract_residence(text),
            'expiry_date': self._extract_expiry(text)
        }
        
        print(f"\nüìä Extracted:")
        for key, value in data.items():
            if value:
                print(f"   ‚úì {key}: {value}")
        print()
        
        return data
    
    def _clean_text(self, text: str) -> str:
        """Clean v√† normalize text"""
        # G·ªôp c√°c d√≤ng ng·∫Øn th√†nh 1 d√≤ng
        text = re.sub(r'\n+', ' ', text)
        # Remove multiple spaces
        text = re.sub(r'\s+', ' ', text)
        return text
    
    def detect_card_type(self, text: str) -> str:
        """Nh·∫≠n di·ªán lo·∫°i gi·∫•y t·ªù"""
        text_upper = text.upper()
        
        if 'CƒÇN C∆Ø·ªöC' in text_upper or 'CITIZEN IDENTITY' in text_upper:
            return 'CƒÉn c∆∞·ªõc c√¥ng d√¢n'
        elif 'CH·ª®NG MINH' in text_upper or 'IDENTITY CARD' in text_upper:
            return 'Ch·ª©ng minh nh√¢n d√¢n'
        elif 'PASSPORT' in text_upper or 'H·ªò CHI·∫æU' in text_upper:
            return 'H·ªô chi·∫øu'
        
        return 'Unknown'
    
    def _extract_id_number(self, text: str) -> Optional[str]:
        """T√¨m s·ªë ID (12 ch·ªØ s·ªë)"""
        match = re.search(r'\b\d{12}\b', text)
        return match.group() if match else None
    
    def _extract_name(self, text: str) -> Optional[str]:
        """T√¨m h·ªç t√™n - c·∫£i thi·ªán v·ªõi spell correction"""
        # Pattern: 2-4 t·ª´ vi·∫øt HOA li√™n ti·∫øp
        pattern = r'\b([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê]{2,}(?:\s+[A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê]{2,}){1,3})\b'
        
        matches = re.findall(pattern, text)
        
        # Blacklist m·ªü r·ªông - th√™m c√°c variation kh√¥ng d·∫•u
        blacklist = [
            'SOCIALIST', 'REPUBLIC', 'VIET', 'NAM', 'VIETNAM', 'CITIZEN', 'IDENTITY', 'CARD',
            'INDEPENDENCE', 'FREEDOM', 'HAPPINESS', 'C√îNG', 'CONG', 'H√ìA', 'HOA', 'H√íA',
            'D√ÇN', 'DAN', 'CƒÇN', 'CAN', 'C∆Ø·ªöC', 'CUOC', 'CH·ª¶', 'CHU', 'CH√ô',
            'NGHƒ®A', 'NGHIA', 'X√É', 'XA', 'H·ªòI', 'HOI', 'VI·ªÜT', 'VIET', 'VET'
        ]
        
        valid_names = []
        
        for name in matches:
            # Skip n·∫øu ch·ª©a keyword
            if any(kw in name.upper().replace(' ', '') for kw in blacklist):
                continue
            
            # Check c√≥ 2-4 t·ª´
            words = name.split()
            if not (2 <= len(words) <= 4):
                continue
            
            # Priority: t√™n ·ªü gi·ªØa text (kh√¥ng ph·∫£i ƒë·∫ßu)
            # T√¨m v·ªã tr√≠ trong text
            pos = text.find(name)
            score = pos / len(text)  # C√†ng xa ƒë·∫ßu c√†ng t·ªët
            
            valid_names.append((name, score))
        
        # S·∫Øp x·∫øp theo score, ch·ªçn t√™n ·ªü gi·ªØa
        if valid_names:
            valid_names.sort(key=lambda x: x[1], reverse=True)
            name = valid_names[0][0]
            # Fix spelling errors
            name = self._fix_name_spelling(name)
            return name
    
        return None
    
    def _fix_name_spelling(self, name: str) -> str:
        """Fix common OCR errors in Vietnamese names"""
        corrections = {
            'NGUYN': 'NGUY·ªÑN',
            'TR√ÇN': 'TR·∫¶N',
            'L': 'L√ä',
            'LE': 'L√ä',
            'PHM': 'PH·∫†M',
            'PHAM': 'PH·∫†M',
            'HU·ª≤H': 'HU·ª≤NH',
            'HUYNH': 'HU·ª≤NH',
            'V√ï': 'V√ï',
            'VO': 'V√ï',
            'D∆Ø∆†NG': 'D∆Ø∆†NG',
            'DUONG': 'D∆Ø∆†NG',
            'B√ôI': 'B√ôI',
            'BUI': 'B√ôI',
            'ƒê√ÄO': 'ƒê√ÄO',
            'DAO': 'ƒê√ÄO',
            'ƒê·ªñ': 'ƒê·ªñ',
            'DO': 'ƒê·ªñ',
        }
        
        words = name.split()
        fixed_words = []
        
        for word in words:
            # Ki·ªÉm tra t·ª´ng t·ª´ c√≥ trong corrections kh√¥ng
            fixed_word = corrections.get(word, word)
            fixed_words.append(fixed_word)
        
        return ' '.join(fixed_words)
    
    def _extract_dob(self, text: str) -> Optional[str]:
        """T√¨m ng√†y sinh (dd/mm/yyyy) - flexible"""
        # T√¨m t·∫•t c·∫£ dates
        dates = re.findall(r'\b(\d{2}/\d{2}/\d{4})\b', text)
        
        current_year = datetime.now().year
        
        for date in dates:
            try:
                day, month, year = map(int, date.split('/'))
                
                # Validate date h·ª£p l·ªá
                if not (1 <= day <= 31 and 1 <= month <= 12):
                    continue
                
                # Ng√†y sinh: t·ª´ 1900 ƒë·∫øn nƒÉm hi·ªán t·∫°i
                if 1900 <= year <= current_year:
                    return date
            except:
                continue
        
        return None
    
    def _extract_gender(self, text: str) -> Optional[str]:
        """T√¨m gi·ªõi t√≠nh - improved with context"""
        # ∆Øu ti√™n t√¨m theo context tr∆∞·ªõc
        patterns = [
            r'(?:Gi·ªõi\s*t√≠nh|Sex)[:\s]+(N·ªØ|Nam|Female|Male)',  # C√≥ context
            r'\b(N·ªØ|Nam|Female|Male)\b'  # Fallback
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                gender = match.group(1)
                # Normalize
                if gender.lower() in ['n·ªØ', 'female']:
                    return 'N·ªØ'
                elif gender.lower() in ['nam', 'male']:
                    return 'Nam'
        
        return None
    
    def _extract_nationality(self, text: str) -> Optional[str]:
        """T√¨m qu·ªëc t·ªãch - improved"""
        patterns = [
            r'Nationality[:\s]+([^\n]+)',
            r'(?:Qu·ªëc\s*t·ªãch|tich)[:\s]+([^\n]+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                line = match.group(1).strip()
                
                # Split b·ªüi c√°c keyword kh√¥ng li√™n quan
                parts = re.split(r'\s+(?:Gi·ªõi|Qu√™|Place|of\s+origin)', line, flags=re.IGNORECASE)
                nationality = parts[0].strip()
                
                # Normalize
                nationality = nationality.replace('Vi√™t', 'Vi·ªát').replace('VIT', 'Vi·ªát').replace('Viet', 'Vi·ªát')
                
                # Validate: ch·ªâ ch·ªØ c√°i v√† space, 2-20 k√Ω t·ª±
                if re.match(r'^[A-Za-z√Ä-·ªπ\s]{2,20}$', nationality):
                    return nationality
        
        return None
    
    def _extract_origin(self, text: str) -> Optional[str]:
        """T√¨m qu√™ qu√°n"""
        patterns = [
            r'origin[:\s]+(.+?)(?:\s+(?:thu√≤ng|thu[o√≤]ng|Noi|Place\s+of\s+residence|C√≥\s+gi√°)|$)',
            r'Qu√™\s+qu√°n[:\s/]+(.+?)(?:\s+N∆°i|$)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                origin = match.group(1).strip()
                
                # Remove junk
                origin = re.sub(r'thu[o√≤]ng\s+', '', origin, flags=re.IGNORECASE)
                origin = re.sub(r'\s+', ' ', origin).strip()
                
                # L·∫•y t·ªëi ƒëa 100 k√Ω t·ª±
                if len(origin) > 100:
                    origin = origin[:100] + '...'
                
                if origin and len(origin) > 3:
                    return origin
        
        return None
    
    def _extract_residence(self, text: str) -> Optional[str]:
        """T√¨m n∆°i th∆∞·ªùng tr√∫ - fixed version"""
        patterns = [
            # Pattern 1: T√¨m gi·ªØa "residence" v√† "Date of expiry" ho·∫∑c "C√≥ gi√°"
            r'residence[:\s]+(.+?)(?=\s*(?:Co|C√≥)\s+gia|Date\s+of\s+expiry|$)',
            # Pattern 2: Ti·∫øng Vi·ªát
            r'Noi\s+thu[o√≤]ng\s+tr[u√∫][:\s/]+(.+?)(?=\s*(?:Co|C√≥)\s+gia|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                residence = match.group(1).strip()
                
                # Aggressive cleaning - remove junk text
                junk_patterns = [
                    r'Noi\s+tr√∫[:/\s]+',
                    r'Place\s+of\s+residence[:\s]+',
                    r'thu[o√≤]ng\s+',
                    r'\s*(?:Co|C√≥)\s+gia.*$',  # Remove "Co gia tri den..."
                    r'\s*Date\s+of.*$',        # Remove "Date of expiry..."
                    r'\s+Place\s+\d+.*$',      # Remove "Place 6"
                    r'\s+Place$',
                ]
                
                for jp in junk_patterns:
                    residence = re.sub(jp, '', residence, flags=re.IGNORECASE)
                
                # Clean spaces and slashes
                residence = re.sub(r'\s+', ' ', residence).strip()
                residence = residence.rstrip('/')
                
                # Validate: ph·∫£i c√≥ √≠t nh·∫•t 1 ch·ªØ c√°i
                if residence and re.search(r'[A-Za-z√Ä-·ªπ]', residence):
                    # L·∫•y t·ªëi ƒëa 100 k√Ω t·ª±
                    if len(residence) > 100:
                        residence = residence[:100] + '...'
                    return residence
        
        return None
    
    def _extract_expiry(self, text: str) -> Optional[str]:
        """T√¨m ng√†y h·∫øt h·∫°n - flexible"""
        patterns = [
            r'(?:C√≥\s+gi√°\s+tr·ªã\s+ƒë·∫øn|Co\s+gia\s+tri\s+den|gi√°\s+trj\s+d√™n)[:\s]+(\d{2}/\d{2}/\d{4})',
            r'(?:Date\s+of\s+)?expiry[:\s]+(\d{2}/\d{2}/\d{4})'
        ]
        
        current_year = datetime.now().year
        
        # Th·ª≠ t√¨m theo pattern tr∆∞·ªõc
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                date = match.group(1)
                try:
                    year = int(date.split('/')[-1])
                    # Ng√†y h·∫øt h·∫°n: t·ª´ nƒÉm hi·ªán t·∫°i ƒë·∫øn +30 nƒÉm
                    if current_year <= year <= current_year + 30:
                        return date
                except:
                    continue
        
        # Fallback: t√¨m date b·∫•t k·ª≥ c√≥ nƒÉm > hi·ªán t·∫°i
        dates = re.findall(r'\b(\d{2}/\d{2}/\d{4})\b', text)
        for date in dates:
            try:
                day, month, year = map(int, date.split('/'))
                
                # Validate date
                if not (1 <= day <= 31 and 1 <= month <= 12):
                    continue
                
                # NƒÉm h·∫øt h·∫°n ph·∫£i > nƒÉm hi·ªán t·∫°i
                if current_year < year <= current_year + 30:
                    return date
            except:
                continue
        
        return None