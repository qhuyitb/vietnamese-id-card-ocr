"""
CCCD Detector - Ph√°t hi·ªán v√† crop c√°c v√πng th√¥ng tin tr√™n CCCD
"""
import sys
from pathlib import Path

# Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path
ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(ROOT))

from ultralytics import YOLO
import cv2
import numpy as np
from typing import List, Dict, Any, Optional

class CCCDDetector:
    """Detector cho CCCD Vi·ªát Nam"""
    
    # 12 classes theo dataset
    CLASS_NAMES = [
        'current_place',  # 0: N∆°i th∆∞·ªùng tr√∫
        'dob',            # 1: Ng√†y sinh
        'expire_date',    # 2: Ng√†y h·∫øt h·∫°n
        'features',       # 3: ƒê·∫∑c ƒëi·ªÉm nh·∫≠n d·∫°ng (m·∫∑t sau)
        'finger_print',   # 4: V√¢n tay (m·∫∑t sau)
        'gender',         # 5: Gi·ªõi t√≠nh
        'id',             # 6: S·ªë CCCD
        'issue_date',     # 7: Ng√†y c·∫•p (m·∫∑t sau)
        'name',           # 8: H·ªç t√™n
        'nationality',    # 9: Qu·ªëc t·ªãch
        'origin_place',   # 10: Qu√™ qu√°n
        'qr'              # 11: M√£ QR
    ]
    
    def __init__(self, model_path: Optional[str] = None, conf_threshold: float = 0.5):
        """
        Initialize CCCD Detector
        
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn model (None = d√πng model m·∫∑c ƒë·ªãnh)
            conf_threshold: Ng∆∞·ª°ng confidence (0-1)
        """
        # N·∫øu kh√¥ng c√≥ model_path, d√πng model trong th∆∞ m·ª•c models/
        if model_path is None:
            model_path = str(ROOT / 'models' / 'cccd_yolo' / 'weights' / 'best.pt')
        
        self.model_path = Path(model_path)
        
        if not self.model_path.exists():
            raise FileNotFoundError(
                f"‚ùå Model kh√¥ng t·ªìn t·∫°i: {model_path}\n"
                f"   Vui l√≤ng train model tr∆∞·ªõc b·∫±ng: python scripts/train_detector.py"
            )
        
        print(f"üì¶ Loading model: {model_path}")
        self.model = YOLO(str(model_path))
        self.conf_threshold = conf_threshold
        print(f"‚úì Model loaded!")
        print(f"‚úì Classes: {len(self.CLASS_NAMES)} classes")
    
    def detect(self, image: np.ndarray, conf: Optional[float] = None) -> List[Dict[str, Any]]:
        """
        Ph√°t hi·ªán c√°c v√πng th√¥ng tin tr√™n CCCD
        
        Args:
            image: ·∫¢nh ƒë·∫ßu v√†o (numpy array BGR)
            conf: Confidence threshold (override default)
            
        Returns:
            List of detections
        """
        conf = conf or self.conf_threshold
        results = self.model(image, conf=conf, verbose=False)
        
        detections = []
        for r in results:
            boxes = r.boxes
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                confidence = float(box.conf[0])
                class_id = int(box.cls[0])
                class_name = self.model.names[class_id]
                
                detections.append({
                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                    'confidence': confidence,
                    'class_id': class_id,
                    'class_name': class_name
                })
        
        # Sort theo class_id ƒë·ªÉ d·ªÖ ƒë·ªçc
        detections.sort(key=lambda x: x['class_id'])
        
        return detections
    
    def detect_and_crop(self, image: np.ndarray, conf: Optional[float] = None) -> Dict[str, np.ndarray]:
        """
        Detect v√† crop c√°c v√πng th√¥ng tin
        
        Returns:
            Dictionary: {class_name: cropped_image}
        """
        detections = self.detect(image, conf)
        
        cropped_regions = {}
        for det in detections:
            class_name = det['class_name']
            bbox = det['bbox']
            cropped = self.crop_bbox(image, bbox)
            
            # N·∫øu c√≥ nhi·ªÅu v√πng c√πng class, th√™m s·ªë th·ª© t·ª±
            if class_name in cropped_regions:
                i = 2
                while f"{class_name}_{i}" in cropped_regions:
                    i += 1
                class_name = f"{class_name}_{i}"
            
            cropped_regions[class_name] = cropped
        
        return cropped_regions
    
    def crop_bbox(self, image: np.ndarray, bbox: List[int]) -> np.ndarray:
        """C·∫Øt v√πng ·∫£nh theo bbox"""
        x1, y1, x2, y2 = bbox
        # ƒê·∫£m b·∫£o bbox n·∫±m trong ·∫£nh
        h, w = image.shape[:2]
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)
        return image[y1:y2, x1:x2]
    
    def visualize(self, image: np.ndarray, conf: Optional[float] = None, 
                  save_path: Optional[str] = None) -> np.ndarray:
        """
        V·∫Ω bounding boxes l√™n ·∫£nh
        """
        detections = self.detect(image, conf)
        result_img = image.copy()
        
        # M√†u cho m·ªói class
        colors = [
            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
            (255, 0, 255), (0, 255, 255), (128, 0, 0), (0, 128, 0),
            (0, 0, 128), (128, 128, 0), (128, 0, 128), (0, 128, 128)
        ]
        
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            class_name = det['class_name']
            class_id = det['class_id']
            confidence = det['confidence']
            
            # Ch·ªçn m√†u theo class_id
            color = colors[class_id % len(colors)]
            
            # V·∫Ω bbox
            cv2.rectangle(result_img, (x1, y1), (x2, y2), color, 2)
            
            # V·∫Ω label v·ªõi background
            label = f"{class_name}: {confidence:.2f}"
            (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(result_img, (x1, y1 - label_h - 10), (x1 + label_w, y1), color, -1)
            cv2.putText(result_img, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        if save_path:
            cv2.imwrite(save_path, result_img)
            print(f"‚úì Saved: {save_path}")
        
        return result_img
    
    def process_image(self, image_path: str, output_dir: Optional[str] = None, 
                     conf: Optional[float] = None) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω m·ªôt ·∫£nh CCCD ho√†n ch·ªânh
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh CCCD
            output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ (optional)
            conf: Confidence threshold
            
        Returns:
            Dictionary ch·ª©a detections v√† cropped regions
        """
        # ƒê·ªçc ·∫£nh
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
        
        print(f"üì∏ Processing: {image_path}")
        
        # Detect
        detections = self.detect(image, conf)
        print(f"‚úì Detected {len(detections)} regions:")
        for det in detections:
            print(f"   - {det['class_name']}: {det['confidence']:.2f}")
        
        # Crop regions
        cropped_regions = self.detect_and_crop(image, conf)
        
        # Visualize
        vis_image = self.visualize(image, conf)
        
        # L∆∞u k·∫øt qu·∫£
        if output_dir:
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # L∆∞u visualization
            img_name = Path(image_path).stem
            vis_path = output_path / f"{img_name}_detected.jpg"
            cv2.imwrite(str(vis_path), vis_image)
            print(f"‚úì Saved visualization: {vis_path}")
            
            # L∆∞u cropped regions
            for class_name, cropped in cropped_regions.items():
                crop_path = output_path / f"{img_name}_{class_name}.jpg"
                cv2.imwrite(str(crop_path), cropped)
            
            print(f"‚úì Saved {len(cropped_regions)} cropped regions")
        
        return {
            'detections': detections,
            'cropped_regions': cropped_regions,
            'visualization': vis_image
        }


# DEMO USAGE
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='CCCD Detection Demo')
    parser.add_argument('--image', type=str, required=True, help='ƒê∆∞·ªùng d·∫´n ·∫£nh CCCD')
    parser.add_argument('--model', type=str, default=None, help='ƒê∆∞·ªùng d·∫´n model (optional)')
    parser.add_argument('--output', type=str, default='output/detections', help='Th∆∞ m·ª•c output')
    parser.add_argument('--conf', type=float, default=0.5, help='Confidence threshold')
    
    args = parser.parse_args()
    
    try:
        # Kh·ªüi t·∫°o detector
        detector = CCCDDetector(model_path=args.model, conf_threshold=args.conf)
        
        # Process image
        results = detector.process_image(
            image_path=args.image,
            output_dir=args.output,
            conf=args.conf
        )
        
        print(f"\n‚úÖ Done! K·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i: {args.output}")
        
    except FileNotFoundError as e:
        print(f"\n‚ùå L·ªói: {e}")
        print("\nƒê·ªÉ train model, ch·∫°y: python scripts/train_detector.py")
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()