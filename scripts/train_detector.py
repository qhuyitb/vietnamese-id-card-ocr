"""
Script ƒë·ªÉ train YOLOv8 model - CCCD Detection
"""
import sys
from pathlib import Path

# Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path
ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(ROOT))

from ultralytics import YOLO
import torch

def train_yolo(data_yaml: str, epochs: int = 100, imgsz: int = 640, model_size: str = 's'):
    """
    Train YOLOv8 cho CCCD detection
    
    Args:
        data_yaml: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file data.yaml
        epochs: S·ªë epochs
        imgsz: K√≠ch th∆∞·ªõc ·∫£nh
        model_size: K√≠ch th∆∞·ªõc model ('n', 's', 'm', 'l', 'x')
    """
    
    # Ki·ªÉm tra GPU
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    print("=" * 60)
    print(f"üîß Device: {device}")
    if torch.cuda.is_available():
        print(f"üéÆ GPU: {torch.cuda.get_device_name(0)}")
        print(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    else:
        print("‚ö†Ô∏è  CPU mode - Training s·∫Ω R·∫§T CH·∫¨M!")
        print("   Khuy·∫øn ngh·ªã: D√πng Google Colab v·ªõi GPU mi·ªÖn ph√≠")
    print("=" * 60)
    
    # Ki·ªÉm tra data.yaml
    data_path = Path(data_yaml)
    if not data_path.exists():
        raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {data_yaml}")
    print(f"‚úì Found data.yaml: {data_yaml}")
    
    # Load pretrained model
    model_name = f'yolov8{model_size}.pt'
    print(f"\nüì¶ Loading pretrained model: {model_name}")
    model = YOLO(model_name)
    print(f"‚úì Model loaded!")
    
    # Training config
    batch_size = 16 if device == 'cuda:0' else 4
    workers = 8 if device == 'cuda:0' else 2
    
    print(f"\nüöÄ Starting training...")
    print(f"   Epochs: {epochs}")
    print(f"   Image size: {imgsz}")
    print(f"   Batch size: {batch_size}")
    print(f"   Workers: {workers}")
    print("=" * 60)
    
    # Train
    results = model.train(
        # Dataset
        data=data_yaml,
        
        # Training parameters
        epochs=epochs,
        imgsz=imgsz,
        batch=batch_size,
        
        # Model saving - L∆ØU V√ÄO TH∆Ø M·ª§C models/
        project=str(ROOT / 'models'),  # L∆∞u v√†o th∆∞ m·ª•c models/
        name='cccd_yolo',
        exist_ok=True,
        
        # Optimization
        patience=50,
        save=True,
        save_period=10,
        
        # Hardware
        device=device,
        workers=workers,
        
        # Data augmentation
        hsv_h=0.015,
        hsv_s=0.7,
        hsv_v=0.4,
        degrees=0.0,
        translate=0.1,
        scale=0.5,
        flipud=0.0,
        fliplr=0.5,
        mosaic=1.0,
        
        # Verbosity
        verbose=True,
        plots=True,
    )
    
    print("\n" + "=" * 60)
    print("‚úÖ TRAINING COMPLETED!")
    print("=" * 60)
    print(f"üìÅ Best model: {results.save_dir}/weights/best.pt")
    print(f"üìÅ Last model: {results.save_dir}/weights/last.pt")
    print(f"üìä Results: {results.save_dir}")
    print("=" * 60)
    
    return results

def validate_model(model_path: str, data_yaml: str):
    """Validate model tr√™n validation set"""
    print(f"\nüìä Validating model: {model_path}")
    
    model = YOLO(model_path)
    metrics = model.val(data=data_yaml)
    
    print("\n" + "=" * 60)
    print("üìà VALIDATION METRICS")
    print("=" * 60)
    print(f"   mAP50:     {metrics.box.map50:.4f}")
    print(f"   mAP50-95:  {metrics.box.map:.4f}")
    print(f"   Precision: {metrics.box.mp:.4f}")
    print(f"   Recall:    {metrics.box.mr:.4f}")
    print("=" * 60)
    
    return metrics

if __name__ == "__main__":
    # C·∫§U H√åNH TRAINING
    
    # ƒê∆∞·ªùng d·∫´n data.yaml 
    DATA_YAML = str(ROOT / 'CCCD_Dataset' / 'data.yaml')
    
    # Training parameters
    EPOCHS = 100        # S·ªë epochs (100-200 epochs cho t·ªët)
    IMG_SIZE = 640      # K√≠ch th∆∞·ªõc ·∫£nh (640 l√† t·ªët nh·∫•t)
    MODEL_SIZE = 's'    # 'n'=nano, 's'=small, 'm'=medium, 'l'=large, 'x'=xlarge
    
    # Ki·ªÉm tra dataset
    print("üîç Checking dataset...")
    dataset_path = ROOT / 'CCCD_Dataset'
    if not dataset_path.exists():
        print(f"‚ùå KH√îNG T√åM TH·∫§Y dataset t·∫°i: {dataset_path}")
        print(f"   Vui l√≤ng ki·ªÉm tra l·∫°i th∆∞ m·ª•c!")
        sys.exit(1)
    
    # Ki·ªÉm tra c√°c th∆∞ m·ª•c con
    for folder in ['train', 'valid', 'test']:
        folder_path = dataset_path / folder
        if not folder_path.exists():
            print(f"‚ö†Ô∏è  C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y folder {folder}/")
        else:
            images_path = folder_path / 'images'
            labels_path = folder_path / 'labels'
            
            if images_path.exists() and labels_path.exists():
                n_images = len(list(images_path.glob('*.jpg'))) + len(list(images_path.glob('*.png')))
                n_labels = len(list(labels_path.glob('*.txt')))
                print(f"‚úì {folder:5s}: {n_images} images, {n_labels} labels")
            else:
                print(f"‚ö†Ô∏è  {folder:5s}: thi·∫øu folder images/ ho·∫∑c labels/")
    
    print("\n" + "=" * 60)
    
    # H·ªèi x√°c nh·∫≠n
    response = input("B·∫Øt ƒë·∫ßu training? (y/n): ")
    if response.lower() != 'y':
        print("‚ùå H·ªßy training")
        sys.exit(0)
    
    # Train model
    try:
        results = train_yolo(
            data_yaml=DATA_YAML,
            epochs=EPOCHS,
            imgsz=IMG_SIZE,
            model_size=MODEL_SIZE
        )
        
        # Validate best model
        best_model_path = f"{results.save_dir}/weights/best.pt"
        validate_model(best_model_path, DATA_YAML)
        
        print("\n‚úÖ Done! Model ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng.")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Training b·ªã ng·∫Øt b·ªüi user")
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()